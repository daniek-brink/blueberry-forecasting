{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daniekbrink/opt/anaconda3/envs/testenv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/daniekbrink/opt/anaconda3/envs/testenv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/daniekbrink/opt/anaconda3/envs/testenv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/daniekbrink/opt/anaconda3/envs/testenv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/daniekbrink/opt/anaconda3/envs/testenv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/daniekbrink/opt/anaconda3/envs/testenv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version: 1.6.0\n",
      "edward version: 1.3.5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"tensorflow version: %s\" % tf.__version__)\n",
    "import edward as ed\n",
    "print(\"edward version: %s\" % ed.__version__)\n",
    "import edward.models as edm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import edward.inferences as edi\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.set_random_seed(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PHASE_SHIFT_DAYS = [21., 18., 11., 5., 3., 0.1]\n",
    "PHASES = 6\n",
    "N = 1\n",
    "PHASE_COLUMNS = ['green', 'colour_break_1', 'colour_break_2', 'pink', 'cherry', 'blue']\n",
    "SAMPLES_WEIGHTS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlueberryModel():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.inputs = None\n",
    "        self.shifts = None\n",
    "        self.grow = None\n",
    "        self.outputs = None\n",
    "        self.latent_vars = None\n",
    "        self.q_grow = None\n",
    "        self.latent_var_dict = None\n",
    "        self.input_ph = None\n",
    "        self.output_ph = None\n",
    "        self.sess = None\n",
    "        self.gamma_params = None\n",
    "        \n",
    "    def build_model(self):\n",
    "        self.inputs = [0] * PHASES\n",
    "        self.shifts = [0] * PHASES\n",
    "        self.grow = [0] * PHASES\n",
    "        self.outputs = [0] * PHASES\n",
    "        for i in range(PHASES):\n",
    "            self.inputs[i] = edm.Normal(20., 7., sample_shape=[N])\n",
    "            shiftmean = self.get_shift_dist(self.inputs[i], PHASE_SHIFT_DAYS[i], PHASE_SHIFT_DAYS[i]/2.)\n",
    "            self.shifts[i] = edm.Normal(shiftmean, PHASE_SHIFT_DAYS[i]/2.)\n",
    "            self.grow[i] = self.shifts[i - 1] if i > 0 else edm.Normal(20.,7., sample_shape=[N])\n",
    "            self.outputs[i] = edm.Normal(self.inputs[i] - self.shifts[i] + self.grow[i], self.inputs[i].scale + self.shifts[i].scale + self.grow[i].scale)\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_shift_dist(n, phase_mean, phase_stddev, days=7.):\n",
    "        p = norm.cdf(days,phase_mean, phase_stddev)\n",
    "        return n * p.astype('float32')\n",
    "    \n",
    "    def build_latent_vars(self):\n",
    "        self.latent_vars = [0] * PHASES\n",
    "        self.q_grow = edm.Normal(loc=tf.Variable(tf.random_uniform([])),\n",
    "                scale=tf.Variable(tf.random_uniform([])), sample_shape=[N])\n",
    "        for i in range(PHASES):\n",
    "            self.latent_vars[i] = edm.Normal(loc=tf.Variable(tf.random_uniform([])),\n",
    "                scale=tf.Variable(tf.random_uniform([])), sample_shape=[N])\n",
    "            \n",
    "    def create_latent_var_dict(self):\n",
    "        self.latent_var_dict = {self.grow[0]: self.q_grow}\n",
    "        self.latent_var_dict.update({key: value for key, value in zip(self.shifts, self.latent_vars)})\n",
    "        \n",
    "    def create_placeholder(self):\n",
    "        placeholder = [0] * PHASES\n",
    "        for i in range(0, PHASES):\n",
    "            placeholder[i] = tf.placeholder(tf.float32, shape=[N])\n",
    "        return placeholder    \n",
    "    \n",
    "    def create_data_dict(self):\n",
    "        self.data_dict = {}\n",
    "        self.data_dict.update({key: value for key, value in zip(self.inputs, self.input_ph)})\n",
    "        self.data_dict.update({key: value for key, value in zip(self.outputs, self.output_ph)})\n",
    "    \n",
    "    def initialize(self):\n",
    "        tf.reset_default_graph()\n",
    "        with tf.name_scope(\"model\"):\n",
    "            self.build_model()\n",
    "        self.sess = ed.get_session()\n",
    "        with tf.name_scope(\"posterior\"):\n",
    "            self.build_latent_vars()\n",
    "            \n",
    "        # Create placeholders for the observed data\n",
    "        self.input_ph = self.create_placeholder()\n",
    "        self.output_ph = self.create_placeholder()\n",
    "        \n",
    "        # Create dictionaries for the latent variables and the observed data (with placeholders for now)\n",
    "        self.create_latent_var_dict()\n",
    "        self.create_data_dict()\n",
    "    \n",
    "    def do_inference(self, samples):\n",
    "        n_batches = samples.shape[0] // N\n",
    "\n",
    "        inf = edi.KLqp(self.latent_var_dict, data=self.data_dict)\n",
    "        inf.initialize(n_iter=100 * n_batches, n_samples=10)\n",
    "\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        for i in range(inf.n_iter):\n",
    "            data_index = i * N % samples.shape[0]\n",
    "\n",
    "            # Populate the placeholders\n",
    "            feed_dict = {}\n",
    "            # Add inputs, one for each phase\n",
    "            feed_dict.update({key: [value] for key, value in zip(self.input_ph, samples[data_index, 0:PHASES])})\n",
    "            # Add outpust, one for each phase\n",
    "            feed_dict.update({key: [value] for key, value in zip(self.output_ph, samples[data_index, PHASES:2*PHASES])})\n",
    "\n",
    "            info_dict = inf.update(feed_dict=feed_dict)\n",
    "            inf.print_progress(info_dict)\n",
    "            \n",
    "    def predict(self, samples):\n",
    "        # copy posterior\n",
    "        x_post = ed.copy(self.outputs[-1], self.latent_var_dict)\n",
    "        sess=self.sess\n",
    "        predictions = np.zeros((samples.shape[0], 3))\n",
    "        for i in range(0, samples.shape[0]):\n",
    "            feed_dict = {}\n",
    "            feed_dict.update({key: [value] for key, value in zip(self.input_ph, samples[i, 0: PHASES])})\n",
    "            quantile_1, quantile_2, mean = sess.run([x_post.quantile(0.025), x_post.quantile(0.975), x_post.mean()], \n",
    "                                                    feed_dict=feed_dict)\n",
    "            predictions[i, :] = [quantile_1, mean, quantile_2]\n",
    "\n",
    "        return predictions\n",
    "            \n",
    "    def evaluate_model(self, samples):\n",
    "        predictions = self.predict(samples[:,0: PHASES])\n",
    "        accuracy = self.calc_accuracy(samples[:, -1], predictions)\n",
    "        print('Model accuracy:', accuracy, '%')\n",
    "        \n",
    "    def fit_weight_prediction(self, weight_data):\n",
    "        self.gamma_params=stats.gamma.fit(weight_data.avg_blueberry_weight)\n",
    "                              \n",
    "        \n",
    "    def predict_weight(self, samples):\n",
    "        \n",
    "        predictions = np.zeros((samples.shape[0], SAMPLES_WEIGHTS))\n",
    "        for i in range(0, SAMPLES_WEIGHTS):\n",
    "            print('Sampling from the blueberry number distribution, iteration:', i)\n",
    "            predictions[:, i] = self.predict(samples)[:,1]\n",
    "        weight_samples = gamma(self.gamma_params[0], self.gamma_params[1], self.gamma_params[2]).rvs((samples.shape[0], SAMPLES_WEIGHTS))\n",
    "        weight_predictions = predictions*weight_samples\n",
    "        mean_weights = np.mean(weight_predictions, axis=1)\n",
    "        stddev_weights = np.std(weight_predictions, axis=1)\n",
    "\n",
    "        return mean_weights, stddev_weights\n",
    "    \n",
    "    def evaluate_weight_prediction(self, weights):\n",
    "        self.fit_weight_prediction(weights)\n",
    "        mean_weights, stddev_weights = self.predict_weight(samples)\n",
    "        _, p_val = stats.kstest(weights.avg_blueberry_weight, 'gamma', args=self.gamma_params)\n",
    "        mse = ((mean_weights - weights.weight.values[:-1])**2).mean()\n",
    "        if p_val < 0.05:\n",
    "            print('This is a bad approximation')\n",
    "        else:\n",
    "            print('The gamma distribution seems to be a good fit.')\n",
    "        print('Mean squared error for blueberry weight prediction:', mse)\n",
    "        \n",
    "    @staticmethod\n",
    "    def calc_accuracy(samples, predictions):\n",
    "        return ((samples > predictions[:,0]) & (samples < predictions[:,2])).sum()/len(samples)*100.\n",
    "    \n",
    "    @staticmethod\n",
    "    def save_model(filename):\n",
    "        saver = tf.train.Saver()\n",
    "        sess = ed.get_session()\n",
    "        save_path = saver.save(sess, filename)\n",
    "        print(\"Model saved to file: %s\" % save_path)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weight = pd.read_csv('weight_data.csv')\n",
    "df_count = pd.read_csv('count_data.csv')\n",
    "df_merge = df_count.merge(df_weight, how='left', on='week')\n",
    "df_merge.loc[:, 'avg_blueberry_weight'] = df_merge.weight/df_merge.blue\n",
    "df_merge = df_merge.replace(np.inf, None).dropna(subset=['avg_blueberry_weight'])\n",
    "# samples used to predict blueberry numbers in last phase\n",
    "df = df_merge[PHASE_COLUMNS]\n",
    "samples = pd.concat([df,df.shift(-1)], axis=1).values[:-1,:] \n",
    "# weight data\n",
    "weights = df_merge[['blue', 'avg_blueberry_weight', 'weight']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1700/1700 [100%] ██████████████████████████████ Elapsed: 18s | Loss: 2796.712\n"
     ]
    }
   ],
   "source": [
    "model = BlueberryModel()\n",
    "model.initialize()\n",
    "model.do_inference(samples)\n",
    "model.fit_weight_prediction(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to file: ./model.cpkt\n"
     ]
    }
   ],
   "source": [
    "model.save_model('./model.cpkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 64.70588235294117 %\n"
     ]
    }
   ],
   "source": [
    "model.evaluate_model(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling from the blueberry number distribution, iteration: 0\n",
      "Sampling from the blueberry number distribution, iteration: 1\n",
      "Sampling from the blueberry number distribution, iteration: 2\n",
      "Sampling from the blueberry number distribution, iteration: 3\n",
      "Sampling from the blueberry number distribution, iteration: 4\n",
      "Sampling from the blueberry number distribution, iteration: 5\n",
      "Sampling from the blueberry number distribution, iteration: 6\n",
      "Sampling from the blueberry number distribution, iteration: 7\n",
      "Sampling from the blueberry number distribution, iteration: 8\n",
      "Sampling from the blueberry number distribution, iteration: 9\n",
      "The gamma distribution seems to be a good fit.\n",
      "Mean squared error for blueberry weight prediction: 0.336432439508296\n"
     ]
    }
   ],
   "source": [
    "model.evaluate_weight_prediction(weights)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
